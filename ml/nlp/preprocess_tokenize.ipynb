{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ingen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ingen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package snowball_data to\n",
      "[nltk_data]     C:\\Users\\ingen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package snowball_data is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ingen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re ## Exprexiones regulares\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk ## Procesamiento de lenguaje natural\n",
    "from nltk.corpus import stopwords ## Palabras vacias\n",
    "from nltk.stem import SnowballStemmer ## Stemming\n",
    "from nltk.tokenize import word_tokenize ## Tokenizacion\n",
    "from nltk.tokenize import RegexpTokenizer ## Tokenizacion\n",
    "from sklearn.feature_extraction.text import CountVectorizer ## Vectorizador\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "# import spacy ## Procesamiento de lenguaje natural\n",
    "\n",
    "############## Descarga de recursos de nltk ################\n",
    "nltk.download('punkt') ## Tokenizador\n",
    "nltk.download('stopwords') ## Palabras vacias\n",
    "nltk.download('snowball_data') ## Stemming\n",
    "nltk.download('wordnet') ## Lematizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Contenido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fundamentos BPR definicion</td>\n",
       "      <td>La reingeniería de procesos de negocio (BPR) e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fundamentos BPR principios clave</td>\n",
       "      <td>Organización alrededor de resultados, no tarea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fundamentos BPR beneficios</td>\n",
       "      <td>Reducción de costos operativos, Mejora en la c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Automatizacion Procesos definicion</td>\n",
       "      <td>La automatización de procesos utiliza tecnolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automatizacion Procesos tecnologias clave</td>\n",
       "      <td>RPA (Robotic Process Automation), BPA (Busines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Categoria  \\\n",
       "0                 Fundamentos BPR definicion   \n",
       "1           Fundamentos BPR principios clave   \n",
       "2                 Fundamentos BPR beneficios   \n",
       "3         Automatizacion Procesos definicion   \n",
       "4  Automatizacion Procesos tecnologias clave   \n",
       "\n",
       "                                           Contenido  \n",
       "0  La reingeniería de procesos de negocio (BPR) e...  \n",
       "1  Organización alrededor de resultados, no tarea...  \n",
       "2  Reducción de costos operativos, Mejora en la c...  \n",
       "3  La automatización de procesos utiliza tecnolog...  \n",
       "4  RPA (Robotic Process Automation), BPA (Busines...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corp = pd.read_csv('./data_raw/proceso_reingenieria_automatizacion_20241130_180543.csv', sep=',') ## Carga de datos\n",
    "df_corp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corp['Contenido_Normalizado'] = df_corp['Contenido'].str.lower()\n",
    "\n",
    "# preprocesamiento de texto\n",
    "def preprocesar_texto(texto):\n",
    "    ## Eliminacion de caracteres especiales\n",
    "    texto = re.sub(r'[^A-Za-z0-9ñáéíóúü ]', '', texto)\n",
    "    ## Tokenizacion\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(texto)\n",
    "    ## Eliminacion de palabras vacias\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    tokens = [i for i in tokens if i not in stop_words]\n",
    "    ## Stemming\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "    tokens = [stemmer.stem(i) for i in tokens]\n",
    "    ## Lematizacion\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(i) for i in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar preprocesamiento\n",
    "df_corp['Contenido_Procesado'] = df_corp['Contenido_Normalizado'].apply(preprocesar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y aplicar TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100, \n",
    "                                 stop_words='english',\n",
    "                                 ngram_range=(1, 2))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_corp['Contenido_Procesado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los términos más relevantes\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "dense = tfidf_matrix.todense()\n",
    "denselist = dense.tolist()\n",
    "scores = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 términos más relevantes según TF-IDF:\n",
      "                 term     score\n",
      "60             proces  2.225034\n",
      "2           automatiz  1.878924\n",
      "92            servici  1.402652\n",
      "93                tar  1.187482\n",
      "95              tiemp  1.048229\n",
      "74            process  1.034839\n",
      "58           prim año  1.000000\n",
      "83            promedi  1.000000\n",
      "0          automation  0.861722\n",
      "15         estandariz  0.826745\n",
      "20             manten  0.807188\n",
      "96         tiemp cicl  0.774114\n",
      "9                cicl  0.774114\n",
      "27              mejor  0.771980\n",
      "65  proces estandariz  0.712948\n"
     ]
    }
   ],
   "source": [
    "# Obtener los top términos por TF-IDF\n",
    "top_terms = pd.DataFrame({\n",
    "    'term': feature_names,\n",
    "    'score': np.array(tfidf_matrix.sum(0)).ravel()\n",
    "}).sort_values('score', ascending=False).head(15)\n",
    "\n",
    "print(\"\\nTop 15 términos más relevantes según TF-IDF:\")\n",
    "print(top_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar NMF para identificar tópicos\n",
    "n_topics = 5\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "nmf_output = nmf_model.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tópicos principales identificados:\n",
      "\n",
      "Tópico 1: automation, process, process automation, automation bpa, rpa\n",
      "\n",
      "Tópico 2: servici, mejor, proces, calid servici, calid\n",
      "\n",
      "Tópico 3: tiemp, tiemp cicl, cicl, reduccion, product\n",
      "\n",
      "Tópico 4: automatiz, tar, proces automatiz, empresarial, proces empresarial\n",
      "\n",
      "Tópico 5: proces, manten, proces simpl, document, proces estandariz\n"
     ]
    }
   ],
   "source": [
    "# Obtener los términos más importantes por tópico\n",
    "def get_topics(model, feature_names, n_top_words):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]]\n",
    "        topics.append(top_words)\n",
    "    return topics\n",
    "\n",
    "topics = get_topics(nmf_model, feature_names, 5)\n",
    "\n",
    "print(\"\\nTópicos principales identificados:\")\n",
    "for idx, topic in enumerate(topics):\n",
    "    print(f\"\\nTópico {idx + 1}: {', '.join(topic)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
